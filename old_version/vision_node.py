#!/usr/bin/env python3
"""
è§†è§‰èŠ‚ç‚¹ - æ„ŸçŸ¥çº¿ç¨‹ï¼ˆPublisherï¼‰
æŒç»­è¿è¡Œ YOLO æ£€æµ‹ï¼Œè®¡ç®—ç©ºé—´åæ ‡ï¼Œè§£ç ç¯è¯­ï¼Œæ›´æ–°å…±äº«çŠ¶æ€
"""

import os
import sys
import cv2
import numpy as np
import time
import math
import re
import threading
from collections import Counter, defaultdict
from ultralytics import YOLO


# ç›¸æœºå®‰è£…æœå‘ï¼ˆæœºä½“åæ ‡ç³»ï¼Œ+Xä¸º0Â°ï¼Œé€†æ—¶é’ˆä¸ºæ­£ï¼‰
CAM_MOUNT_YAW_DEG = {
    0: 180.0,  # cam0 -> -Xï¼ˆåæ–¹ï¼‰
    2: -90.0,  # cam2 -> -Yï¼ˆå³ä¾§ï¼‰
    4: 0.0,    # cam4 -> +Xï¼ˆå‰æ–¹ï¼‰
    6: 90.0,   # cam6 -> +Yï¼ˆå·¦ä¾§ï¼‰
}


def wrap_deg_360(a):
    """å°†è§’åº¦å½’ä¸€åŒ–åˆ° [0, 360) èŒƒå›´"""
    return (a + 360.0) % 360.0


def create_camera_matrix(f_x=498, f_y=498, c_x=331.2797, c_y=156.1371):
    """åˆ›å»ºç›¸æœºå†…å‚çŸ©é˜µ"""
    return np.array([
        [f_x, 0, c_x],
        [0, f_y, c_y],
        [0, 0, 1]
    ])


def calculate_azimuth_planar(x_pixel, camera_params, debug=False):
    """åŸºäºå¹³é¢å‡ ä½•çš„æ–¹ä½è§’è®¡ç®—"""
    fx = camera_params.get('fx', 498)
    cx = camera_params.get('cx', 331.2797)
    
    pixel_offset = x_pixel - cx
    angle_rad = math.atan(pixel_offset / fx)
    angle_deg = math.degrees(angle_rad)
    
    if angle_deg < 0:
        azimuth = 360 + angle_deg
    else:
        azimuth = angle_deg
    
    return azimuth


def calculate_distance_planar(detected_width, real_width, fx, debug=False):
    """åŸºäºæ£€æµ‹æ¡†å®½åº¦çš„è·ç¦»è®¡ç®—"""
    if detected_width <= 0:
        return float('inf')
    
    distance = (real_width * fx) / detected_width
    return distance


class VisionNode:
    """
    è§†è§‰èŠ‚ç‚¹ - åªè´Ÿè´£æ„ŸçŸ¥
    ä¸æ‰§è¡Œä»»ä½•æœºå™¨äººæ§åˆ¶ï¼Œåªæ›´æ–°å…±äº«çŠ¶æ€
    """
    
    def __init__(self, robot_state, model_path, camera_indices=[0, 2, 4, 6]):
        """
        åˆå§‹åŒ–è§†è§‰èŠ‚ç‚¹
        
        Args:
            robot_state: RobotState å®ä¾‹
            model_path: YOLO æ¨¡å‹è·¯å¾„
            camera_indices: æ‘„åƒå¤´ç´¢å¼•åˆ—è¡¨
        """
        self.robot_state = robot_state
        self.model_path = model_path
        self.camera_indices = camera_indices
        
        # ç›¸æœºå‚æ•°
        self.frame_width = 640
        self.frame_height = 480
        self.real_width = 0.31  # ç›®æ ‡çœŸå®å®½åº¦ï¼ˆç±³ï¼‰
        self.camera_matrix = create_camera_matrix()
        self.camera_matrix_inv = np.linalg.inv(self.camera_matrix)
        
        # ç¯è¯­æ¨¡å¼åˆ°åŠ¨ä½œçš„æ˜ å°„
        self.PATTERN_TO_COMMAND = {
            '220': 'FORWARD', '330': 'LEFT', '110': 'RIGHT', '550': 'REVERSE', '440': 'STOP',
            '2200': 'APPROACH', '1100': 'RETREAT', '4400': 'S_SHAPE', '5500': 'CIRCLE',
            '1111': 'FORWARD', '2222': 'LEFT', '3333': 'RIGHT', '4444': 'STOP', '5555': 'REVERSE',
        }
        
        # åŠ¨ä½œæè¿°
        self.ACTION_DESCRIPTIONS = {
            'FORWARD': 'å‰è¿›', 'LEFT': 'å·¦ç§»', 'RIGHT': 'å³ç§»', 'STOP': 'åœæ­¢',
            'REVERSE': 'åé€€', 'APPROACH': 'é è¿‘', 'RETREAT': 'è¿œç¦»', 
            'S_SHAPE': 'Så½¢', 'CIRCLE': 'åœ†å½¢', 'IDLE': 'å¾…æœº'
        }
        
        # çº¿ç¨‹æ§åˆ¶
        self.stop_event = threading.Event()
        self.thread = None
        self.running = False
        
        # ä¸´æ—¶æ£€æµ‹ç¼“å­˜ï¼ˆç”¨äºç¯è¯­è¯†åˆ«ï¼‰
        self.detection_buffer = defaultdict(list)  # {cam_idx: []}
        self.buffer_lock = threading.Lock()

        print("âœ… è§†è§‰èŠ‚ç‚¹åˆå§‹åŒ–å®Œæˆ")

    def initialize_camera(self, cam_idx):
        """åˆå§‹åŒ–å•ä¸ªæ‘„åƒå¤´"""
        try:
            cap = cv2.VideoCapture(cam_idx, cv2.CAP_V4L2)
            if not cap.isOpened():
                cap = cv2.VideoCapture(cam_idx)

            if cap.isOpened():
                cap.set(cv2.CAP_PROP_FRAME_WIDTH, self.frame_width)
                cap.set(cv2.CAP_PROP_FRAME_HEIGHT, self.frame_height)
                cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)
                cap.set(cv2.CAP_PROP_FOURCC, cv2.VideoWriter_fourcc(*'MJPG'))

                # æµ‹è¯•è¯»å–
                time.sleep(0.3)
                ret, frame = cap.read()
                if ret and frame is not None:
                    print(f'âœ… æ‘„åƒå¤´ {cam_idx} åˆå§‹åŒ–æˆåŠŸ')
                    return cap
                else:
                    cap.release()
                    return None
            return None
        except Exception as e:
            print(f'âŒ æ‘„åƒå¤´ {cam_idx} åˆå§‹åŒ–é”™è¯¯: {e}')
            return None

    def camera_worker(self, cam_idx):
        """å•ä¸ªæ‘„åƒå¤´çš„å·¥ä½œçº¿ç¨‹"""
        print(f'ğŸš€ å¯åŠ¨è§†è§‰çº¿ç¨‹ - æ‘„åƒå¤´ {cam_idx}')

        # åŠ è½½æ¨¡å‹
        try:
            model = YOLO(self.model_path)
            print(f'âœ… æ‘„åƒå¤´ {cam_idx} æ¨¡å‹åŠ è½½æˆåŠŸ')
        except Exception as e:
            print(f'âŒ æ‘„åƒå¤´ {cam_idx} æ¨¡å‹åŠ è½½å¤±è´¥: {e}')
            return

        # åˆå§‹åŒ–æ‘„åƒå¤´
        cap = self.initialize_camera(cam_idx)
        if cap is None:
            print(f'âŒ æ‘„åƒå¤´ {cam_idx} åˆå§‹åŒ–å¤±è´¥ï¼Œçº¿ç¨‹é€€å‡º')
            return

        frame_count = 0
        consec_fail = 0

        try:
            while not self.stop_event.is_set():
                ret, frame = cap.read()
                if not ret or frame is None:
                    consec_fail += 1
                    if consec_fail >= 30:
                        print(f'âš ï¸ æ‘„åƒå¤´ {cam_idx} è¿ç»­è¯»å¸§å¤±è´¥ï¼Œé€€å‡º')
                        break
                    time.sleep(0.05)
                    continue

                consec_fail = 0
                frame_count += 1

                # æ‰§è¡Œæ£€æµ‹
                try:
                    results = model.track(frame, conf=0.55, iou=0.6, imgsz=(480, 640), persist=True,verbose=False)

                    if results[0].boxes is not None:
                        for box in results[0].boxes:
                            class_id = int(box.cls.item())
                            confidence = float(box.conf.item())
                            track_id = int(box.id.item()) if box.id is not None else -1

                            if track_id < 0:
                                continue

                            x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
                            x_center = (x1 + x2) / 2
                            box_width = x2 - x1

                            # è®¡ç®—è·ç¦»å’Œæ–¹ä½è§’
                            fx = 1.0 / self.camera_matrix_inv[0][0]
                            cx = -self.camera_matrix_inv[0][2] * fx

                            distance = calculate_distance_planar(box_width, self.real_width, fx)
                            camera_params = {'fx': fx, 'cx': cx}
                            azimuth = calculate_azimuth_planar(x_center, camera_params)

                            # è½¬æ¢åˆ°æœºä½“åæ ‡ç³»
                            cam_mount_yaw = CAM_MOUNT_YAW_DEG.get(cam_idx, 0.0)
                            bearing_body = wrap_deg_360(cam_mount_yaw + azimuth)

                            # å­˜å‚¨æ£€æµ‹ä¿¡æ¯ï¼ˆç”¨äºç¯è¯­è¯†åˆ«ï¼‰
                            with self.buffer_lock:
                                self.detection_buffer[cam_idx].append({
                                    'track_id': track_id,
                                    'class_id': class_id,
                                    'distance': distance,
                                    'azimuth': azimuth,
                                    'bearing_body': bearing_body,
                                    'timestamp': time.time(),
                                    'frame_count': frame_count
                                })

                                # é™åˆ¶ç¼“å­˜å¤§å°
                                if len(self.detection_buffer[cam_idx]) > 200:
                                    self.detection_buffer[cam_idx] = self.detection_buffer[cam_idx][-200:]

                            # ç®€å•çš„ç¯è¯­è¯†åˆ«ï¼ˆåŸºäºç±»åˆ«IDå˜åŒ–ï¼‰
                            # è¿™é‡Œç®€åŒ–å¤„ç†ï¼Œå®é™…å¯ä»¥æ ¹æ®æ£€æµ‹å†å²è¿›è¡Œæ›´å¤æ‚çš„åˆ†æ
                            command = self.recognize_pattern(cam_idx, track_id)

                            # æ›´æ–°å…±äº«çŠ¶æ€
                            self.robot_state.update_perception(
                                distance=distance,
                                azimuth=azimuth,
                                bearing_body=bearing_body,
                                track_id=track_id,
                                cam_idx=cam_idx,
                                command=command,
                                command_params={
                                    'description': self.ACTION_DESCRIPTIONS.get(command, 'æœªçŸ¥')
                                },
                                class_id=class_id
                            )

                except Exception as e:
                    print(f'âŒ æ‘„åƒå¤´ {cam_idx} æ¨ç†é”™è¯¯: {e}')
                    time.sleep(0.1)

        finally:
            cap.release()
            print(f'ğŸ è§†è§‰çº¿ç¨‹ç»“æŸ - æ‘„åƒå¤´ {cam_idx}')

    def recognize_pattern(self, cam_idx, track_id):
        """
        ç®€åŒ–çš„ç¯è¯­è¯†åˆ«
        è¿™é‡Œä½¿ç”¨ç®€å•çš„å¯å‘å¼è§„åˆ™ï¼Œå®é™…åº”ç”¨ä¸­å¯ä»¥ä½¿ç”¨æ›´å¤æ‚çš„ç®—æ³•
        """
        with self.buffer_lock:
            # è·å–è¯¥ track_id çš„æœ€è¿‘æ£€æµ‹
            recent_detections = [d for d in self.detection_buffer[cam_idx]
                               if d['track_id'] == track_id and time.time() - d['timestamp'] < 3.0]

            if len(recent_detections) < 10:
                return 'IDLE'

            # ç»Ÿè®¡ç±»åˆ«ID
            class_ids = [d['class_id'] for d in recent_detections[-36:]]  # æœ€è¿‘36å¸§

            # ç»Ÿè®¡0å’Œé0çš„æ¯”ä¾‹
            zero_count = sum(1 for cid in class_ids if cid == 0)
            non_zero_count = len(class_ids) - zero_count

            if non_zero_count == 0:
                return 'IDLE'

            non_zero_class = max(set([cid for cid in class_ids if cid != 0]),
                               key=class_ids.count, default=0)

            if zero_count == 0:
                # å…¨æ˜¯éé›¶ -> xxxx æ¨¡å¼
                pattern = f'{non_zero_class}{non_zero_class}{non_zero_class}{non_zero_class}'
            elif non_zero_count / max(1, zero_count) > 1.8:
                # éé›¶å¤š -> xx0 æ¨¡å¼
                pattern = f'{non_zero_class}{non_zero_class}0'
            else:
                # æ¯”è¾ƒå‡è¡¡ -> xx00 æ¨¡å¼
                pattern = f'{non_zero_class}{non_zero_class}00'

            return self.PATTERN_TO_COMMAND.get(pattern, 'IDLE')

    def start(self):
        """å¯åŠ¨è§†è§‰èŠ‚ç‚¹"""
        if self.running:
            print("âš ï¸ è§†è§‰èŠ‚ç‚¹å·²åœ¨è¿è¡Œ")
            return

        self.stop_event.clear()
        self.running = True

        # ä¸ºæ¯ä¸ªæ‘„åƒå¤´å¯åŠ¨çº¿ç¨‹
        self.threads = []
        for cam_idx in self.camera_indices:
            thread = threading.Thread(target=self.camera_worker, args=(cam_idx,), daemon=True)
            thread.start()
            self.threads.append(thread)
            time.sleep(0.3)  # é”™å¼€å¯åŠ¨æ—¶é—´

        print("âœ… è§†è§‰èŠ‚ç‚¹å·²å¯åŠ¨")

    def stop(self):
        """åœæ­¢è§†è§‰èŠ‚ç‚¹"""
        if not self.running:
            return

        print("ğŸ›‘ æ­£åœ¨åœæ­¢è§†è§‰èŠ‚ç‚¹...")
        self.stop_event.set()

        for thread in self.threads:
            thread.join(timeout=2.0)

        self.running = False
        print("âœ… è§†è§‰èŠ‚ç‚¹å·²åœæ­¢")


# 多线程"伪ROS"架构 - 感知与控制解耦系统

## 📋 概述

这是一个将原始单体架构重构为**多线程解耦架构**的系统，实现了类似 ROS 的发布-订阅模式，但不依赖 ROS 库。

### 核心目标
- ✅ **感知与行动完全解耦**：视觉检测和机器人控制在不同线程中并行运行
- ✅ **边看边动**：控制线程基于实时的最新感知数据进行决策
- ✅ **线程安全**：使用线程锁保护共享状态的读写
- ✅ **超时保护**：自动检测数据超时并执行安全停止

---

## 🏗️ 架构设计

```
┌─────────────────────────────────────────────────────────────┐
│                      主系统 (main_system.py)                  │
│                         单进程、多线程                          │
└─────────────────────────────────────────────────────────────┘
                              │
                ┌─────────────┼─────────────┐
                │             │             │
        ┌───────▼──────┐ ┌───▼────┐ ┌──────▼───────┐
        │ VisionNode   │ │ State  │ │ ControlNode  │
        │ (Publisher)  │ │(Topic) │ │ (Subscriber) │
        │              │ │        │ │              │
        │ 4x 摄像头     │ │ 线程锁  │ │ 控制循环      │
        │ YOLO 检测    ├─►        ◄─┤ @20Hz        │
        │ 灯语识别     │ │        │ │ PID控制      │
        │              │ │        │ │              │
        └──────────────┘ └────────┘ └──────────────┘
           (持续更新)      (共享内存)     (持续读取)
```

---

## 📁 文件结构

```
pseudo_ros_architecture/
├── robot_shared_state.py  # 共享状态（话题）
├── vision_node.py         # 视觉节点（发布者）
├── control_node.py        # 控制节点（订阅者）
├── main_system.py         # 主系统入口
└── README.md              # 本文档
```

### 各模块职责

#### 1. `robot_shared_state.py` - 共享状态
- **角色**：通信中枢（类似 ROS Topic）
- **功能**：
  - 存储最新的目标信息（距离、角度、TrackID）
  - 存储当前指令（APPROACH、STOP 等）
  - 提供线程安全的读写接口
  - 超时检测

#### 2. `vision_node.py` - 视觉节点
- **角色**：发布者（只管看）
- **功能**：
  - 并行处理4个摄像头
  - YOLO 目标检测
  - 计算距离和方位角
  - 灯语识别
  - **仅更新共享状态，不调用任何控制函数**

#### 3. `control_node.py` - 控制节点
- **角色**：订阅者（只管动）
- **功能**：
  - 运行独立的控制循环（20Hz）
  - 从共享状态读取最新数据
  - 超时检查（1秒超时 → 安全停止）
  - 执行机器人控制（PID、轨迹规划等）
  - **不进行任何视觉处理**

#### 4. `main_system.py` - 主系统
- **角色**：入口点
- **功能**：
  - 初始化所有组件
  - 启动和停止线程
  - 信号处理（Ctrl+C 优雅退出）

---

## 🚀 使用方法

### 1. 运行系统

```bash
cd /home/nvidia/Downloads/ros/pseudo_ros_architecture
python3 main_system.py
```

### 2. Mock 模式（无机器人控制）

如果机器人控制模块不可用，系统会自动进入 Mock 模式，仅打印日志而不发送控制指令。

你也可以在 `main_system.py` 中手动设置：

```python
system = PseudoROSSystem(
    model_path=model_path,
    robot_id=8,
    enable_control=False,  # 设置为 False 进入 Mock 模式
    camera_indices=[0, 2, 4, 6]
)
```

### 3. 停止系统

按 `Ctrl+C`，系统会自动：
1. 停止控制节点（安全停止机器人）
2. 停止视觉节点（释放摄像头）
3. 清理资源

---

## ⚙️ 关键参数配置

### 视觉节点参数
- **摄像头索引**：`camera_indices=[0, 2, 4, 6]`
- **YOLO 置信度**：`conf=0.55`
- **IoU 阈值**：`iou=0.6`
- **相机内参**：`fx=498, cx=331.2797` (在 `vision_node.py` 中)

### 控制节点参数
- **控制频率**：`control_hz=20.0` (20Hz)
- **超时时间**：`target_timeout=1.0` (1秒)
- **靠近目标距离**：`target_distance=0.5` (0.5米)
- **远离安全距离**：`retreat_target_distance=2.0` (2.0米)

### 相机安装朝向
在 `vision_node.py` 中配置（机体坐标系，+X为0°）：

```python
CAM_MOUNT_YAW_DEG = {
    0: 180.0,  # cam0 -> 后方
    2: -90.0,  # cam2 -> 右侧
    4: 0.0,    # cam4 -> 前方
    6: 90.0,   # cam6 -> 左侧
}
```

---

## 🔧 与原始代码的主要改进

| 特性 | 原始单体架构 | 新多线程架构 |
|------|-------------|-------------|
| 感知与控制 | 紧密耦合，互相阻塞 | 完全解耦，并行运行 |
| 延迟 | 高延迟（检测完才能动） | 低延迟（实时响应） |
| 数据新鲜度 | 使用历史数据（.txt文件） | 使用最新数据（共享内存） |
| 安全性 | 无超时保护 | 自动超时检测 + 安全停止 |
| 可维护性 | 1500行单文件 | 模块化，职责清晰 |

---

## 🎯 典型执行流程

### 场景：检测到"靠近"指令

```
[视觉线程]                    [共享状态]                [控制线程]
    │                            │                         │
    ├─ 检测到目标 (TrackID=5)     │                         │
    ├─ 计算距离=2.0m             │                         │
    ├─ 计算角度=45°              │                         │
    ├─ 识别灯语='2200'           │                         │
    ├─ 映射指令='APPROACH'        │                         │
    │                            │                         │
    ├─► update_perception() ────►│                         │
    │                            │◄──── get_latest_state() ─┤
    │                            │                         ├─ 检测到新指令
    ├─ 继续检测下一帧...          │                         ├─ 执行 approach()
    ├─ 更新距离=1.8m             │                         │   - 计算速度
    ├─► update_perception() ────►│                         │   - 发送控制指令
    │                            │◄──── get_latest_state() ─┤
    │                            │                         ├─ 读取最新距离
    │                            │                         ├─ 调整速度
    ├─ 继续检测...               │                         │
    ⋮                            ⋮                         ⋮
```

---

## ⚠️ 注意事项

1. **模型路径**：确保 YOLO 模型路径正确
2. **摄像头权限**：需要访问 `/dev/video*` 的权限
3. **依赖库**：需要安装 `opencv-python`, `ultralytics`, `numpy`
4. **机器人控制**：如果控制模块不可用，会自动进入 Mock 模式

---

## 🐛 调试技巧

### 查看系统状态
在 `main_system.py` 中，`run_forever()` 方法会定期打印系统状态。

### 增加日志输出
可以在各节点中添加更多 `print()` 语句来跟踪执行流程。

### 测试单个模块
```python
# 测试共享状态
from robot_shared_state import RobotState
state = RobotState()
state.update_perception(1.5, 45.0, 90.0, 5, 0, 'APPROACH')
print(state.get_latest_state())
```

---

## 📚 扩展方向

1. **多目标处理**：当前只处理单个目标，可扩展为多目标优先级调度
2. **历史轨迹**：在共享状态中记录目标运动轨迹，实现预测控制
3. **性能监控**：添加 FPS、延迟等性能指标的统计
4. **动态调参**：支持运行时修改控制参数（如超时时间、控制频率）

---

**作者**: AI 辅助重构  
**日期**: 2024  
**版本**: 1.0


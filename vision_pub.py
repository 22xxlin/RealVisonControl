#!/usr/bin/env python3
"""
æ–‡ä»¶: vision_pub.py (é²æ£’å¢å¼ºç‰ˆ V2.0)
åŠŸèƒ½: è§†è§‰æ„ŸçŸ¥å‘å¸ƒ
å‡çº§ç‚¹:
  1. å¼•å…¥æ–½å¯†ç‰¹è§¦å‘å™¨ (è¿Ÿæ»é˜ˆå€¼) é˜²æ­¢ FLASH/SOLID è·³å˜
  2. å¼•å…¥çŠ¶æ€æ—¶é—´é”å®š (State Locking) é˜²æ­¢é«˜é¢‘åˆ‡æ¢
  3. ZMQ è¾“å‡ºé™é¢‘ (10Hz)
"""

import os
import sys
import cv2
import numpy as np
import time
import math
import json
import zmq
import queue
import threading
from collections import defaultdict, deque
from ultralytics import YOLO

# ================= é…ç½®åŒºåŸŸ =================
MODEL_PATH = "/home/nvidia/Downloads/Ros/ballCar2/weights/weights/best.engine"
CAMERA_INDICES = [0, 2, 4, 6]
ZMQ_PORT = 5555
PUBLISH_RATE_LIMIT = 0.1  # é™åˆ¶ ZMQ å‘é€é—´éš”è‡³å°‘ 0.1s (10Hz)
STATE_LOCK_DURATION = 0.5 # çŠ¶æ€åˆ‡æ¢åé”å®š 0.5sï¼Œé˜²æ­¢æŠ–åŠ¨

# çœŸå®å®½åº¦ (å•ä½: ç±³)
CLASS_REAL_WIDTHS = {
    "car": 0.31,
    "basketball": 0.23,
    "flag": 0.13
}

# Class ID æ˜ å°„
CLS_MAP = {
    0: "OFF", 1: "BLUE", 2: "RED", 3: "GREEN", 
    4: "PURPLE", 5: "GRAY", 6: "BALL", 7: "FLAG"
}

# ç›¸æœºæœå‘
CAM_MOUNT_YAW_DEG = {0: 180.0, 2: -90.0, 4: 0.0, 6: 90.0}

# ================= è¾…åŠ©å‡½æ•° =================
def create_camera_matrix(f_x=498, f_y=498, c_x=331.2797, c_y=156.1371):
    return np.array([[f_x, 0, c_x], [0, f_y, c_y], [0, 0, 1]])

def calculate_azimuth_planar(x_pixel, camera_params):
    fx = camera_params.get('fx', 498)
    cx = camera_params.get('cx', 331.2797)
    pixel_offset = x_pixel - cx
    angle_rad = math.atan(pixel_offset / fx)
    angle_deg = math.degrees(angle_rad)
    return (angle_deg + 360.0) % 360.0 if angle_deg < 0 else angle_deg

def wrap_deg_360(a):
    return (a + 360.0) % 360.0

# ================= ä¸»ç±»å®šä¹‰ =================
class VisionPublisher:
    def __init__(self, model_path, camera_indices, zmq_port=5555, debounce_maxlen=30):
        self.model_path = model_path
        self.camera_indices = camera_indices
        self.zmq_port = zmq_port
        
        self.camera_matrix = create_camera_matrix()
        self.camera_matrix_inv = np.linalg.inv(self.camera_matrix)
        self.fx = 1.0 / self.camera_matrix_inv[0][0]
        self.cx = -self.camera_matrix_inv[0][2] * self.fx

        self.queue = queue.Queue(maxsize=100)
        self.context = zmq.Context()
        self.socket = self.context.socket(zmq.PUB)
        self.socket.bind(f"tcp://*:{self.zmq_port}")
        
        # å†å²ç¼“å­˜: Key=(cam_idx, track_id)
        self.history = defaultdict(lambda: deque(maxlen=debounce_maxlen))
        
        # âš ï¸ æ–°å¢ï¼šçŠ¶æ€è®°å¿†ä¸é”å®š
        # memory[key] = {'state': 'IDLE', 'pattern': 'OFF', 'last_switch_time': 0.0}
        self.state_memory = defaultdict(lambda: {'state': 0, 'pattern': 'OFF', 'last_switch_time': 0.0})
        
        # âš ï¸ æ–°å¢ï¼šå‘å¸ƒé™é¢‘è®°å½•
        self.last_pub_time = 0.0

        print(f"âœ… è§†è§‰å‘å¸ƒè€…å¯åŠ¨ (é²æ£’ç‰ˆ) | æ¨¡å‹: {self.model_path}")

    def initialize_camera(self, cam_idx):
        try:
            cap = cv2.VideoCapture(cam_idx, cv2.CAP_V4L2)
            if not cap.isOpened(): cap = cv2.VideoCapture(cam_idx)
            if cap.isOpened():
                cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
                cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
                cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)
                cap.set(cv2.CAP_PROP_FOURCC, cv2.VideoWriter_fourcc(*'MJPG'))
                return cap
        except Exception: pass
        return None

    def get_stable_state(self, cam_idx, track_id, current_class_id):
        """
        æ ¸å¿ƒé€»è¾‘å‡çº§ï¼šè¿Ÿæ»æ¯”è¾ƒ (Hysteresis) + çŠ¶æ€é”å®š
        """
        key = (cam_idx, track_id)
        mem = self.state_memory[key]
        now = time.time()

        # 1. ç‰¹æ®Šç‰©ä½“ç›´æ¥è¿”å›
        if current_class_id >= 6:
            return current_class_id, "SOLID"

        # 2. å­˜å…¥å†å² Buffer
        self.history[key].append(current_class_id)
        buffer = list(self.history[key])

        # 3. ç»Ÿè®¡é¢œè‰²
        colored_frames = [c for c in buffer if c in [1, 2, 3, 4, 5]]
        if not colored_frames:
            return 0, "OFF"

        from collections import Counter
        counts = Counter(colored_frames)
        dominant_color, count = counts.most_common(1)[0]
        
        # 4. è®¡ç®—å æ¯”
        total_len = len(buffer)
        color_ratio = count / total_len
        
        # 5. âš ï¸ è¿Ÿæ»é€»è¾‘ (Schmitt Trigger)
        # ä¸Šä¸€æ¬¡æ˜¯ SOLID
        if mem['pattern'] == 'SOLID':
            # åªæœ‰æ¯”ä¾‹æ‰åˆ° 0.80 ä»¥ä¸‹ï¼Œæ‰é™çº§ä¸º FLASH
            if color_ratio < 0.80:
                new_pattern = 'FLASH'
            else:
                new_pattern = 'SOLID'
        # ä¸Šä¸€æ¬¡æ˜¯ FLASH æˆ– OFF
        else:
            # åªæœ‰æ¯”ä¾‹å†²è¿‡ 0.90ï¼Œæ‰å‡çº§ä¸º SOLID
            if color_ratio > 0.90:
                new_pattern = 'SOLID'
            else:
                new_pattern = 'FLASH'

        # 6. âš ï¸ æ—¶é—´é”å®š (é˜²æ­¢ç™«ç—«å¼åˆ‡æ¢)
        # å¦‚æœæ–°çŠ¶æ€å’Œæ—§çŠ¶æ€ä¸ä¸€æ ·
        if new_pattern != mem['pattern'] or dominant_color != mem['state']:
            # æ£€æŸ¥æ˜¯å¦è¿˜åœ¨é”å®šæ—¶é—´å†…
            if now - mem['last_switch_time'] < STATE_LOCK_DURATION:
                # è¿˜åœ¨å†·å´ï¼Œä¿æŒæ—§çŠ¶æ€
                return mem['state'], mem['pattern']
            else:
                # å†·å´ç»“æŸï¼Œå…è®¸åˆ‡æ¢ï¼Œå¹¶æ›´æ–°æ—¶é—´æˆ³
                mem['state'] = dominant_color
                mem['pattern'] = new_pattern
                mem['last_switch_time'] = now
                return dominant_color, new_pattern
        else:
            # çŠ¶æ€æ²¡å˜ï¼Œç›´æ¥æ›´æ–°æ—¶é—´æˆ³(å¯é€‰)æˆ–ä¿æŒ
            return dominant_color, new_pattern

    def calculate_distance(self, box_width, class_id):
        if class_id == 6: real_w = CLASS_REAL_WIDTHS["basketball"]
        elif class_id == 7: real_w = CLASS_REAL_WIDTHS["flag"]
        else: real_w = CLASS_REAL_WIDTHS["car"]
        if box_width <= 0: return 999.0
        return (real_w * self.fx) / box_width

    def camera_worker(self, cam_idx):
        try:
            model = YOLO(self.model_path)
            self.queue.put({'type': 'log', 'message': f'âœ… Cam {cam_idx}: Ready'})
        except Exception as e:
            self.queue.put({'type': 'log', 'message': f'âŒ Cam {cam_idx}: {e}'})
            return

        cap = self.initialize_camera(cam_idx)
        if cap is None: return

        try:
            while True:
                ret, frame = cap.read()
                if not ret: 
                    time.sleep(0.1); continue

                # é™ä½ç½®ä¿¡åº¦ï¼Œä¾èµ–åå¤„ç†è¿‡æ»¤
                results = model.track(frame, conf=0.45, iou=0.6, imgsz=(480, 640), persist=True, verbose=False)

                if results[0].boxes is not None:
                    for box in results[0].boxes:
                        raw_class_id = int(box.cls.item())
                        track_id = int(box.id.item()) if box.id is not None else -1
                        if track_id < 0: continue

                        x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
                        x_center = (x1 + x2) / 2
                        box_width = x2 - x1

                        stable_class, pattern = self.get_stable_state(cam_idx, track_id, raw_class_id)
                        
                        # è¿‡æ»¤æ— æ•ˆçŠ¶æ€
                        if stable_class == 0: continue

                        distance = self.calculate_distance(box_width, stable_class)
                        azimuth = calculate_azimuth_planar(x_center, {'fx': self.fx, 'cx': self.cx})
                        bearing_body = wrap_deg_360(CAM_MOUNT_YAW_DEG.get(cam_idx, 0.0) + azimuth)

                        if distance < 6.0:
                            data = {
                                'type': 'detection',
                                'cam_idx': cam_idx,
                                'track_id': track_id,
                                'class_id': stable_class,
                                'pattern': pattern,
                                'distance': round(distance, 2),
                                'bearing_body': round(bearing_body, 2)
                            }
                            try: self.queue.put_nowait(data)
                            except queue.Full: pass
        except Exception as e:
            print(f"Cam {cam_idx} Error: {e}")
        finally:
            cap.release()

    def run(self):
        print('ğŸš€ è§†è§‰ç³»ç»Ÿè¿è¡Œä¸­ (10Hz é™é¢‘è¾“å‡º)...')
        
        threads = []
        for idx in self.camera_indices:
            t = threading.Thread(target=self.camera_worker, args=(idx,), daemon=True)
            t.start()
            threads.append(t)

        try:
            while True:
                data = self.queue.get()
                
                if data['type'] == 'log':
                    print(data['message'])
                
                elif data['type'] == 'detection':
                    # âš ï¸ 7. å…¨å±€é™é¢‘ (Throttle)
                    now = time.time()
                    if now - self.last_pub_time > PUBLISH_RATE_LIMIT:
                        
                        topic = "perception"
                        pub_data = {k:v for k,v in data.items() if k != 'type'}
                        self.socket.send_string(f"{topic} {json.dumps(pub_data)}")
                        self.last_pub_time = now # æ›´æ–°å‘é€æ—¶é—´
                        
                        # è°ƒè¯•æ‰“å°
                        cls_name = CLS_MAP.get(pub_data['class_id'], "UNK")
                        print(f"ğŸ‘ï¸ [{cls_name}-{pub_data['cam_idx']}] {pub_data['pattern']:<5} | D={pub_data['distance']}m")

                self.queue.task_done()
        except KeyboardInterrupt:
            print("ğŸ›‘ åœæ­¢ä¸­...")

    def cleanup(self):
        self.socket.close()
        self.context.term()

if __name__ == "__main__":
    pub = VisionPublisher(MODEL_PATH, CAMERA_INDICES, ZMQ_PORT)
    try:
        pub.run()
    except KeyboardInterrupt:
        pass
    finally:
        pub.cleanup()
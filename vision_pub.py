#!/usr/bin/env python3
"""
è§†è§‰å‘å¸ƒè€… - ä½¿ç”¨ ZeroMQ PUB å‘å¸ƒæ£€æµ‹ç»“æœ
ç‹¬ç«‹è¿›ç¨‹ï¼Œæ›¿ä»£åŸæœ¬çš„ VisionNode çº¿ç¨‹

æ¶æ„ï¼šç”Ÿäº§è€…-æ¶ˆè´¹è€…æ¨¡å‹ï¼ˆProducer-Consumerï¼‰
- ç”Ÿäº§è€…ï¼ˆ4ä¸ªå­çº¿ç¨‹ï¼‰ï¼šæ¯ä¸ªæ‘„åƒå¤´ç‹¬ç«‹è¿è¡Œ camera_workerï¼Œè¯»å›¾ã€YOLOæ£€æµ‹ã€ç¯è¯­è¯†åˆ«
  å°†æ£€æµ‹æ•°æ®é€šè¿‡çº¿ç¨‹å®‰å…¨é˜Ÿåˆ— (queue.Queue) å‘é€ç»™æ¶ˆè´¹è€…
- æ¶ˆè´¹è€…ï¼ˆä¸»çº¿ç¨‹ï¼‰ï¼šä»é˜Ÿåˆ—ä¸­å–æ•°æ®ï¼Œç»Ÿä¸€è´Ÿè´£ ZMQ å‘é€å’Œæ—¥å¿—æ‰“å°
  ç¡®ä¿ ZMQ Socket çš„çº¿ç¨‹å®‰å…¨ï¼ˆSocket ä¸æ˜¯çº¿ç¨‹å®‰å…¨çš„ï¼Œåªèƒ½åœ¨ä¸»çº¿ç¨‹æ“ä½œï¼‰
"""

import os
import sys
import cv2
import numpy as np
import time
import math
import json
import zmq
import queue
import threading
from collections import defaultdict
from ultralytics import YOLO


# ç›¸æœºå®‰è£…æœå‘ï¼ˆæœºä½“åæ ‡ç³»ï¼Œ+Xä¸º0Â°ï¼Œé€†æ—¶é’ˆä¸ºæ­£ï¼‰
CAM_MOUNT_YAW_DEG = {
    0: 180.0,  # cam0 -> -Xï¼ˆåæ–¹ï¼‰
    2: -90.0,  # cam2 -> -Yï¼ˆå³ä¾§ï¼‰
    4: 0.0,    # cam4 -> +Xï¼ˆå‰æ–¹ï¼‰
    6: 90.0,   # cam6 -> +Yï¼ˆå·¦ä¾§ï¼‰
}


def wrap_deg_360(a):
    """å°†è§’åº¦å½’ä¸€åŒ–åˆ° [0, 360) èŒƒå›´"""
    return (a + 360.0) % 360.0


def create_camera_matrix(f_x=498, f_y=498, c_x=331.2797, c_y=156.1371):
    """åˆ›å»ºç›¸æœºå†…å‚çŸ©é˜µ"""
    return np.array([
        [f_x, 0, c_x],
        [0, f_y, c_y],
        [0, 0, 1]
    ])


def calculate_azimuth_planar(x_pixel, camera_params):
    """åŸºäºå¹³é¢å‡ ä½•çš„æ–¹ä½è§’è®¡ç®—"""
    fx = camera_params.get('fx', 498)
    cx = camera_params.get('cx', 331.2797)
    
    pixel_offset = x_pixel - cx
    angle_rad = math.atan(pixel_offset / fx)
    angle_deg = math.degrees(angle_rad)
    
    if angle_deg < 0:
        azimuth = 360 + angle_deg
    else:
        azimuth = angle_deg
    
    return azimuth


def calculate_distance_planar(detected_width, real_width, fx):
    """åŸºäºæ£€æµ‹æ¡†å®½åº¦çš„è·ç¦»è®¡ç®—"""
    if detected_width <= 0:
        return float('inf')
    
    distance = (real_width * fx) / detected_width
    return distance


class VisionPublisher:
    """è§†è§‰å‘å¸ƒè€… - ä½¿ç”¨ ZeroMQ å‘å¸ƒæ£€æµ‹ç»“æœ"""
    
    def __init__(self, model_path, camera_indices=[0, 2, 4, 6], zmq_port=5555):
        """
        åˆå§‹åŒ–è§†è§‰å‘å¸ƒè€…
        
        Args:
            model_path: YOLO æ¨¡å‹è·¯å¾„
            camera_indices: æ‘„åƒå¤´ç´¢å¼•åˆ—è¡¨
            zmq_port: ZeroMQ å‘å¸ƒç«¯å£
        """
        self.model_path = model_path
        self.camera_indices = camera_indices
        self.zmq_port = zmq_port
        
        # ç›¸æœºå‚æ•°
        self.frame_width = 640
        self.frame_height = 480
        self.real_width = 0.31  # ç›®æ ‡çœŸå®å®½åº¦ï¼ˆç±³ï¼‰
        self.camera_matrix = create_camera_matrix()
        self.camera_matrix_inv = np.linalg.inv(self.camera_matrix)
        
        # ç¯è¯­æ¨¡å¼åˆ°åŠ¨ä½œçš„æ˜ å°„
        self.PATTERN_TO_COMMAND = {
            '220': 'FORWARD', '330': 'LEFT', '110': 'RIGHT', '550': 'REVERSE', '440': 'STOP',
            '2200': 'APPROACH', '1100': 'RETREAT', '4400': 'S_SHAPE', '5500': 'CIRCLE',
            '1111': 'FORWARD', '2222': 'LEFT', '3333': 'RIGHT', '4444': 'STOP', '5555': 'REVERSE',
        }
        
        # åŠ¨ä½œæè¿°
        self.ACTION_DESCRIPTIONS = {
            'FORWARD': 'å‰è¿›', 'LEFT': 'å·¦ç§»', 'RIGHT': 'å³ç§»', 'STOP': 'åœæ­¢',
            'REVERSE': 'åé€€', 'APPROACH': 'é è¿‘', 'RETREAT': 'è¿œç¦»', 
            'S_SHAPE': 'Så½¢', 'CIRCLE': 'åœ†å½¢', 'IDLE': 'å¾…æœº'
        }
        
        # ä¸´æ—¶æ£€æµ‹ç¼“å­˜ï¼ˆç”¨äºç¯è¯­è¯†åˆ«ï¼‰
        self.detection_buffer = defaultdict(list)  # {cam_idx: []}

        # çº¿ç¨‹å®‰å…¨é˜Ÿåˆ—ï¼ˆç”Ÿäº§è€…-æ¶ˆè´¹è€…æ¨¡å‹ï¼‰
        self.queue = queue.Queue(maxsize=100)

        # åˆå§‹åŒ– ZeroMQ
        self.context = zmq.Context()
        self.socket = self.context.socket(zmq.PUB)
        self.socket.bind(f"tcp://*:{self.zmq_port}")

        print(f"âœ… è§†è§‰å‘å¸ƒè€…åˆå§‹åŒ–å®Œæˆ - ZMQ ç»‘å®šåˆ° tcp://*:{self.zmq_port}")

    def initialize_camera(self, cam_idx):
        """åˆå§‹åŒ–å•ä¸ªæ‘„åƒå¤´"""
        try:
            cap = cv2.VideoCapture(cam_idx, cv2.CAP_V4L2)
            if not cap.isOpened():
                cap = cv2.VideoCapture(cam_idx)

            if cap.isOpened():
                cap.set(cv2.CAP_PROP_FRAME_WIDTH, self.frame_width)
                cap.set(cv2.CAP_PROP_FRAME_HEIGHT, self.frame_height)
                cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)
                cap.set(cv2.CAP_PROP_FOURCC, cv2.VideoWriter_fourcc(*'MJPG'))

                # æµ‹è¯•è¯»å–
                time.sleep(0.3)
                ret, frame = cap.read()
                if ret and frame is not None:
                    print(f'âœ… æ‘„åƒå¤´ {cam_idx} åˆå§‹åŒ–æˆåŠŸ')
                    return cap
                else:
                    cap.release()
                    return None
            return None
        except Exception as e:
            print(f'âŒ æ‘„åƒå¤´ {cam_idx} åˆå§‹åŒ–é”™è¯¯: {e}')
            return None

    def recognize_pattern(self, cam_idx, track_id):
        """
        ç®€åŒ–çš„ç¯è¯­è¯†åˆ«
        åŸºäºç±»åˆ«IDå˜åŒ–è¯†åˆ«ç¯è¯­æ¨¡å¼
        """
        # è·å–è¯¥ track_id çš„æœ€è¿‘æ£€æµ‹
        recent_detections = [d for d in self.detection_buffer[cam_idx]
                           if d['track_id'] == track_id and time.time() - d['timestamp'] < 3.0]

        if len(recent_detections) < 10:
            return 'IDLE'

        # ç»Ÿè®¡ç±»åˆ«ID
        class_ids = [d['class_id'] for d in recent_detections[-36:]]  # æœ€è¿‘36å¸§

        # ç»Ÿè®¡0å’Œé0çš„æ¯”ä¾‹
        zero_count = sum(1 for cid in class_ids if cid == 0)
        non_zero_count = len(class_ids) - zero_count

        if non_zero_count == 0:
            return 'IDLE'

        non_zero_class = max(set([cid for cid in class_ids if cid != 0]),
                           key=class_ids.count, default=0)

        if zero_count == 0:
            # å…¨æ˜¯éé›¶ -> xxxx æ¨¡å¼
            pattern = f'{non_zero_class}{non_zero_class}{non_zero_class}{non_zero_class}'
        elif non_zero_count / max(1, zero_count) > 1.8:
            # éé›¶å¤š -> xx0 æ¨¡å¼
            pattern = f'{non_zero_class}{non_zero_class}0'
        else:
            # æ¯”è¾ƒå‡è¡¡ -> xx00 æ¨¡å¼
            pattern = f'{non_zero_class}{non_zero_class}00'

        return self.PATTERN_TO_COMMAND.get(pattern, 'IDLE')



    def camera_worker(self, cam_idx):
        """
        å•ä¸ªæ‘„åƒå¤´çš„å·¥ä½œå¾ªç¯ï¼ˆç”Ÿäº§è€…çº¿ç¨‹ï¼‰
        ä¸ç›´æ¥æ“ä½œ socket å’Œ printï¼Œè€Œæ˜¯å°†æ•°æ®æ”¾å…¥é˜Ÿåˆ—
        """
        # åŠ è½½æ¨¡å‹
        try:
            model = YOLO(self.model_path)
            # é€šè¿‡é˜Ÿåˆ—å‘é€åˆå§‹åŒ–æˆåŠŸæ¶ˆæ¯
            self.queue.put({
                'type': 'log',
                'message': f'âœ… æ‘„åƒå¤´ {cam_idx} æ¨¡å‹åŠ è½½æˆåŠŸ'
            })
        except Exception as e:
            self.queue.put({
                'type': 'log',
                'message': f'âŒ æ‘„åƒå¤´ {cam_idx} æ¨¡å‹åŠ è½½å¤±è´¥: {e}'
            })
            return

        # åˆå§‹åŒ–æ‘„åƒå¤´
        cap = self.initialize_camera(cam_idx)
        if cap is None:
            self.queue.put({
                'type': 'log',
                'message': f'âŒ æ‘„åƒå¤´ {cam_idx} åˆå§‹åŒ–å¤±è´¥ï¼Œé€€å‡º'
            })
            return

        frame_count = 0
        consec_fail = 0

        try:
            while True:
                ret, frame = cap.read()
                if not ret or frame is None:
                    consec_fail += 1
                    if consec_fail >= 30:
                        self.queue.put({
                            'type': 'log',
                            'message': f'âš ï¸ æ‘„åƒå¤´ {cam_idx} è¿ç»­è¯»å¸§å¤±è´¥ï¼Œé€€å‡º'
                        })
                        break
                    time.sleep(0.05)
                    continue

                consec_fail = 0
                frame_count += 1

                # æ‰§è¡Œæ£€æµ‹ï¼ˆé™éŸ³æ¨¡å¼ï¼‰
                try:
                    results = model.track(frame, conf=0.55, iou=0.6, imgsz=(480, 640), persist=True)

                    if results[0].boxes is not None:
                        for box in results[0].boxes:
                            class_id = int(box.cls.item())
                            track_id = int(box.id.item()) if box.id is not None else -1

                            if track_id < 0:
                                continue

                            x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
                            x_center = (x1 + x2) / 2
                            box_width = x2 - x1

                            # è®¡ç®—è·ç¦»å’Œæ–¹ä½è§’
                            fx = 1.0 / self.camera_matrix_inv[0][0]
                            cx = -self.camera_matrix_inv[0][2] * fx

                            distance = calculate_distance_planar(box_width, self.real_width, fx)
                            camera_params = {'fx': fx, 'cx': cx}
                            azimuth = calculate_azimuth_planar(x_center, camera_params)

                            # è½¬æ¢åˆ°æœºä½“åæ ‡ç³»
                            cam_mount_yaw = CAM_MOUNT_YAW_DEG.get(cam_idx, 0.0)
                            bearing_body = wrap_deg_360(cam_mount_yaw + azimuth)

                            # å­˜å‚¨æ£€æµ‹ä¿¡æ¯ï¼ˆç”¨äºç¯è¯­è¯†åˆ«ï¼‰
                            self.detection_buffer[cam_idx].append({
                                'track_id': track_id,
                                'class_id': class_id,
                                'distance': distance,
                                'azimuth': azimuth,
                                'bearing_body': bearing_body,
                                'timestamp': time.time(),
                                'frame_count': frame_count
                            })

                            # é™åˆ¶ç¼“å­˜å¤§å°
                            if len(self.detection_buffer[cam_idx]) > 200:
                                self.detection_buffer[cam_idx] = self.detection_buffer[cam_idx][-200:]

                            # ç¯è¯­è¯†åˆ«
                            command = self.recognize_pattern(cam_idx, track_id)

                            # æ‰“åŒ…æ•°æ®å¹¶æ”¾å…¥é˜Ÿåˆ—ï¼ˆä¸ç›´æ¥å‘é€ï¼‰
                            detection_data = {
                                'type': 'detection',
                                'distance': float(distance),
                                'azimuth': float(azimuth),
                                'bearing_body': float(bearing_body),
                                'track_id': int(track_id),
                                'cam_idx': int(cam_idx),
                                'command': command,
                                'description': self.ACTION_DESCRIPTIONS.get(command, 'æœªçŸ¥'),
                                'class_id': int(class_id),
                                'timestamp': time.time()
                            }

                            # ä½¿ç”¨ put_nowaitï¼Œå¦‚æœé˜Ÿåˆ—æ»¡äº†å°±ä¸¢å¼ƒ
                            try:
                                self.queue.put_nowait(detection_data)
                            except queue.Full:
                                # é˜Ÿåˆ—æ»¡äº†ï¼Œä¸¢å¼ƒè¯¥å¸§æ•°æ®
                                pass

                except Exception as e:
                    self.queue.put({
                        'type': 'log',
                        'message': f'âŒ æ‘„åƒå¤´ {cam_idx} æ¨ç†é”™è¯¯: {e}'
                    })
                    time.sleep(0.1)

        except KeyboardInterrupt:
            self.queue.put({
                'type': 'log',
                'message': f'\nâš ï¸ æ‘„åƒå¤´ {cam_idx} æ”¶åˆ°ä¸­æ–­ä¿¡å·'
            })
        finally:
            cap.release()
            self.queue.put({
                'type': 'log',
                'message': f'ğŸ è§†è§‰å‘å¸ƒè€…ç»“æŸ - æ‘„åƒå¤´ {cam_idx}'
            })

    def run(self):
        """
        è¿è¡Œè§†è§‰å‘å¸ƒè€…ï¼ˆå¤šæ‘„åƒå¤´å¹¶è¡Œæ¨¡å¼ï¼‰
        ä¸»çº¿ç¨‹ä½œä¸ºæ¶ˆè´¹è€…ï¼Œè´Ÿè´£ä»é˜Ÿåˆ—å–æ•°æ®å¹¶å‘é€ ZMQ æ¶ˆæ¯
        """
        print(f'ğŸš€ å¯åŠ¨è§†è§‰å‘å¸ƒè€… - å¤šæ‘„åƒå¤´å¹¶è¡Œæ¨¡å¼')
        print(f'ğŸ“¹ æ‘„åƒå¤´åˆ—è¡¨: {self.camera_indices}')

        # å¯åŠ¨æ‰€æœ‰æ‘„åƒå¤´çš„ç”Ÿäº§è€…çº¿ç¨‹
        threads = []
        for cam_idx in self.camera_indices:
            thread = threading.Thread(
                target=self.camera_worker,
                args=(cam_idx,),
                daemon=True,
                name=f"Camera-{cam_idx}"
            )
            thread.start()
            threads.append(thread)
            print(f'âœ… æ‘„åƒå¤´ {cam_idx} çº¿ç¨‹å·²å¯åŠ¨')

        print(f'\nğŸ“¡ ä¸»çº¿ç¨‹å¼€å§‹æ¶ˆè´¹é˜Ÿåˆ—æ•°æ®...\n')

        # ä¸»çº¿ç¨‹ä½œä¸ºæ¶ˆè´¹è€…ï¼Œä¸æ–­ä»é˜Ÿåˆ—å–æ•°æ®
        try:
            while True:
                # é˜»å¡ç­‰å¾…é˜Ÿåˆ—æ•°æ®
                data = self.queue.get()

                # å¤„ç†ä¸åŒç±»å‹çš„æ¶ˆæ¯
                if data.get('type') == 'log':
                    # æ—¥å¿—æ¶ˆæ¯ï¼Œç›´æ¥æ‰“å°
                    print(data['message'])

                elif data.get('type') == 'detection':
                    # æ£€æµ‹æ•°æ®ï¼Œé€šè¿‡ ZMQ å‘é€
                    topic = "perception"

                    # ç§»é™¤ type å­—æ®µï¼Œåªå‘é€æ£€æµ‹æ•°æ®
                    detection_data = {k: v for k, v in data.items() if k != 'type'}
                    message = json.dumps(detection_data)
                    self.socket.send_string(f"{topic} {message}")

                    # ç®€æ´çš„ç»ˆç«¯æ—¥å¿—
                    cmd = detection_data.get('command', 'IDLE')
                    dist = detection_data.get('distance', 0)
                    bearing = detection_data.get('bearing_body', 0)
                    track_id = detection_data.get('track_id', -1)
                    cam_idx = detection_data.get('cam_idx', -1)

                    if cmd != 'IDLE':
                        print(f"ğŸ¥ [Cam{cam_idx}] Sent: {cmd} | Dist={dist:.2f}m | Bearing={bearing:.1f}Â° | TrackID={track_id}")

                # æ ‡è®°ä»»åŠ¡å®Œæˆ
                self.queue.task_done()

        except KeyboardInterrupt:
            print('\n\nâš ï¸ ä¸»çº¿ç¨‹æ”¶åˆ°ä¸­æ–­ä¿¡å·ï¼Œç­‰å¾…å­çº¿ç¨‹ç»“æŸ...')
            # ç­‰å¾…æ‰€æœ‰çº¿ç¨‹ç»“æŸï¼ˆæœ€å¤šç­‰å¾…5ç§’ï¼‰
            for thread in threads:
                thread.join(timeout=5.0)
            print('âœ… æ‰€æœ‰æ‘„åƒå¤´çº¿ç¨‹å·²ç»“æŸ')

    def cleanup(self):
        """æ¸…ç†èµ„æº"""
        self.socket.close()
        self.context.term()
        print("âœ… ZeroMQ èµ„æºå·²æ¸…ç†")


if __name__ == "__main__":
    # é…ç½®å‚æ•°
    MODEL_PATH = "/home/nvidia/Downloads/Ros/0821Car3/weights/best.engine"  # ä¿®æ”¹ä¸ºä½ çš„æ¨¡å‹è·¯å¾„
    CAMERA_INDICES = [0, 2, 4, 6]  # 4ä¸ªæ‘„åƒå¤´å¹¶è¡Œå·¥ä½œï¼šåã€å³ã€å‰ã€å·¦
    ZMQ_PORT = 5555

    print("=" * 60)
    print("ğŸ¥ è§†è§‰å‘å¸ƒè€… (ZeroMQ PUB) - å¤šæ‘„åƒå¤´å¹¶è¡Œæ¨¡å¼")
    print("=" * 60)
    print(f"ğŸ“¡ å‘å¸ƒåœ°å€: tcp://*:{ZMQ_PORT}")
    print(f"ğŸ“¹ æ‘„åƒå¤´: {CAMERA_INDICES}")
    print(f"   - Cam0: åæ–¹ (180Â°)")
    print(f"   - Cam2: å³ä¾§ (-90Â°)")
    print(f"   - Cam4: å‰æ–¹ (0Â°)")
    print(f"   - Cam6: å·¦ä¾§ (90Â°)")
    print(f"ğŸ¤– æ¨¡å‹è·¯å¾„: {MODEL_PATH}")
    print(f"ğŸ”„ æ¶æ„: ç”Ÿäº§è€…-æ¶ˆè´¹è€…æ¨¡å‹ (4ä¸ªç”Ÿäº§è€…çº¿ç¨‹ + 1ä¸ªæ¶ˆè´¹è€…ä¸»çº¿ç¨‹)")
    print("=" * 60)
    print("æŒ‰ Ctrl+C åœæ­¢\n")

    # åˆ›å»ºå¹¶è¿è¡Œå‘å¸ƒè€…
    publisher = VisionPublisher(
        model_path=MODEL_PATH,
        camera_indices=CAMERA_INDICES,
        zmq_port=ZMQ_PORT
    )

    try:
        publisher.run()
    except KeyboardInterrupt:
        print("\n\nğŸ›‘ æ”¶åˆ°åœæ­¢ä¿¡å·")
    finally:
        publisher.cleanup()
        print("ğŸ‘‹ è§†è§‰å‘å¸ƒè€…å·²é€€å‡º")


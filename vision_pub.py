#!/usr/bin/env python3
"""
æ–‡ä»¶: vision_pub.py (V3.1 è°ƒè¯•ç‰ˆ)
åŠŸèƒ½: è§†è§‰æ„ŸçŸ¥å‘å¸ƒ
å‡çº§ç‚¹:
  1. è¾“å‡º fused (èåˆ), geo (å‡ ä½•), width (å®½åº¦) ä¸‰ç§è·ç¦»ä¾›æ•°æ®è®°å½•ã€‚
  2. ä¿®å¤äº† Tuple å¯¹æ¯” Float çš„ç±»å‹é”™è¯¯ã€‚
  3. ZMQ è¾“å‡ºé™é¢‘ (10Hz).
"""

import os
import sys
import cv2
import numpy as np
import time
import math
import json
import zmq
import queue
import threading
from collections import defaultdict, deque
from ultralytics import YOLO

# ================= é…ç½®åŒºåŸŸ =================
MODEL_PATH = "/home/nvidia/Downloads/Ros/ballCar2/weights/weights/best.engine"
CAMERA_INDICES = [0, 2, 4, 6]
ZMQ_PORT = 5555
PUBLISH_RATE_LIMIT = 0.05  # é™åˆ¶ ZMQ å‘é€é—´éš” (10Hz)
STATE_LOCK_DURATION = 0.5 # çŠ¶æ€åˆ‡æ¢é”å®šæ—¶é—´

# === ç‰©ç†ä¸å‡ ä½•å‚æ•° ===
# çœŸå®å®½åº¦ (å•ä½: ç±³)
CLASS_REAL_WIDTHS = {
    "car": 0.31,
    "basketball": 0.23,
    "flag": 0.13
}

# å‡ ä½•æµ‹è·é«˜åº¦å‚æ•° (å•ä½: ç±³)
CAM_HEIGHT = 0.15      # ç›¸æœºç¦»åœ°é«˜åº¦
OBJ_HEIGHT = 0.20      # å°è½¦å¡”é¡¶é«˜åº¦ (ä»…ç”¨äº 0-5 ç±»)

# ç›¸æœºå†…å‚ (è¯·æ ¹æ®å®é™…æ ‡å®šä¿®æ”¹)
CAM_INTRINSICS = {
    'fx': 498.0,
    'fy': 498.0,
    'cx': 331.2797,
    'cy': 156.1371
}

# Class ID æ˜ å°„
CLS_MAP = {
    0: "OFF", 1: "BLUE", 2: "RED", 3: "GREEN", 
    4: "PURPLE", 5: "GRAY", 6: "BALL", 7: "FLAG"
}

# ç›¸æœºæœå‘
CAM_MOUNT_YAW_DEG = {0: 180.0, 2: -90.0, 4: 0.0, 6: 90.0}

# ================= è¾…åŠ©å‡½æ•° =================
def calculate_azimuth_planar(x_pixel, fx, cx):
    pixel_offset = x_pixel - cx
    angle_rad = math.atan(pixel_offset / fx)
    angle_deg = math.degrees(angle_rad)
    return (angle_deg + 360.0) % 360.0 if angle_deg < 0 else angle_deg

def wrap_deg_360(a):
    return (a + 360.0) % 360.0

# ================= ä¸»ç±»å®šä¹‰ =================
class VisionPublisher:
    def __init__(self, model_path, camera_indices, zmq_port=5555, debounce_maxlen=30):
        self.model_path = model_path
        self.camera_indices = camera_indices
        self.zmq_port = zmq_port
        
        # åŠ è½½å†…å‚
        self.fx = CAM_INTRINSICS['fx']
        self.fy = CAM_INTRINSICS['fy']
        self.cx = CAM_INTRINSICS['cx']
        self.cy = CAM_INTRINSICS['cy']

        self.queue = queue.Queue(maxsize=100)
        self.context = zmq.Context()
        self.socket = self.context.socket(zmq.PUB)
        self.socket.bind(f"tcp://*:{self.zmq_port}")
        
        # å†å²ç¼“å­˜: Key=(cam_idx, track_id)
        self.history = defaultdict(lambda: deque(maxlen=debounce_maxlen))
        
        # çŠ¶æ€è®°å¿†
        self.state_memory = defaultdict(lambda: {'state': 0, 'pattern': 'OFF', 'last_switch_time': 0.0})
        
        # å‘å¸ƒé™é¢‘
        self.last_pub_time = 0.0

        print(f"âœ… è§†è§‰å‘å¸ƒè€…å¯åŠ¨ (è°ƒè¯•ç‰ˆ V3.1) | æ¨¡å‹: {self.model_path}")

    def initialize_camera(self, cam_idx):
        try:
            cap = cv2.VideoCapture(cam_idx, cv2.CAP_V4L2)
            if not cap.isOpened(): cap = cv2.VideoCapture(cam_idx)
            if cap.isOpened():
                cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
                cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
                cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)
                cap.set(cv2.CAP_PROP_FOURCC, cv2.VideoWriter_fourcc(*'MJPG'))
                return cap
        except Exception: pass
        return None

    def get_stable_state(self, cam_idx, track_id, current_class_id):
        """
        è¿Ÿæ»æ¯”è¾ƒ (Hysteresis) + çŠ¶æ€é”å®š
        """
        key = (cam_idx, track_id)
        mem = self.state_memory[key]
        now = time.time()

        if current_class_id >= 6: return current_class_id, "SOLID"

        self.history[key].append(current_class_id)
        buffer = list(self.history[key])

        colored_frames = [c for c in buffer if c in [1, 2, 3, 4, 5]]
        if not colored_frames: return 0, "OFF"

        from collections import Counter
        counts = Counter(colored_frames)
        dominant_color, count = counts.most_common(1)[0]
        color_ratio = count / len(buffer)
        
        if mem['pattern'] == 'SOLID':
            new_pattern = 'FLASH' if color_ratio < 0.80 else 'SOLID'
        else:
            new_pattern = 'SOLID' if color_ratio > 0.90 else 'FLASH'

        if new_pattern != mem['pattern'] or dominant_color != mem['state']:
            if now - mem['last_switch_time'] < STATE_LOCK_DURATION:
                return mem['state'], mem['pattern']
            else:
                mem['state'] = dominant_color
                mem['pattern'] = new_pattern
                mem['last_switch_time'] = now
                return dominant_color, new_pattern
        else:
            return dominant_color, new_pattern

    def calculate_fused_distance(self, bbox_xyxy, class_id):
        """
        ğŸ”¥ æ ¸å¿ƒå‡çº§ï¼šåŒæ—¶è¿”å› (èåˆå€¼, å‡ ä½•å€¼, å®½åº¦å€¼)
        """
        x1, y1, x2, y2 = bbox_xyxy
        box_width = x2 - x1
        box_height = y2 - y1
        
        # 1. åŸºç¡€æ£€æŸ¥
        if box_width <= 0 or box_height <= 0: 
            return 999.0, -1.0, -1.0

        # --- A. å®½åº¦æµ‹è·æ³• (é€šç”¨) ---
        if class_id == 6: real_w = CLASS_REAL_WIDTHS["basketball"]
        elif class_id == 7: real_w = CLASS_REAL_WIDTHS["flag"]
        else: real_w = CLASS_REAL_WIDTHS["car"]
        
        dist_width = (real_w * self.fx) / box_width
        
        # é»˜è®¤å€¼
        dist_geo = -1.0
        fused_dist = dist_width

        # --- B. èåˆé€»è¾‘ (ä»…é’ˆå¯¹å°è½¦ 0-5) ---
        if 0 <= class_id <= 5:
            # 1. å‡ ä½•æµ‹è· (å‡è®¾å€’ç«‹æ‘„åƒå¤´ï¼Œå– y2 ä¸ºå¡”é¡¶)
            y_top_pixel = y2 
            v = y_top_pixel - self.cy
            
            if abs(v) < 1e-5: v = 1e-5
            
            # è®¡ç®—ä¿¯ä»°è§’
            alpha = math.atan(v / self.fy)
            total_angle = alpha + 0.0 
            
            dH = OBJ_HEIGHT - CAM_HEIGHT
            
            if total_angle > 0.001:
                dist_geo = abs(dH / math.tan(total_angle))
            else:
                dist_geo = 99.9 

            # 2. å®½é«˜æ¯”æ£€æŸ¥ (é®æŒ¡æ£€æµ‹)
            current_ratio = box_width / box_height
            OCCLUSION_THRESHOLD = 0.9 

            if dist_geo < 15.0: 
                if current_ratio < OCCLUSION_THRESHOLD:
                    # âš ï¸ åˆ¤å®šä¸ºé®æŒ¡ -> å…¨ä¿¡å‡ ä½•æ³•
                    fused_dist = dist_geo
                else:
                    # âœ… åˆ¤å®šä¸ºæ­£å¸¸ -> åŠ æƒèåˆ
                    fused_dist = 0.4 * dist_geo + 0.6 * dist_width
            else:
                fused_dist = dist_width
        
        # éå°è½¦ (çƒã€æ——å­) ç›´æ¥è¿”å›å®½åº¦è·ç¦»ï¼Œdist_geo ä¿æŒ -1.0
        return fused_dist, dist_geo, dist_width

    def camera_worker(self, cam_idx):
        try:
            model = YOLO(self.model_path)
            self.queue.put({'type': 'log', 'message': f'âœ… Cam {cam_idx}: Ready'})
        except Exception as e:
            self.queue.put({'type': 'log', 'message': f'âŒ Cam {cam_idx}: {e}'})
            return

        cap = self.initialize_camera(cam_idx)
        if cap is None: return

        try:
            while True:
                ret, frame = cap.read()
                if not ret: 
                    time.sleep(0.1); continue

                results = model.track(frame, conf=0.45, iou=0.6, imgsz=(480, 640), persist=True, verbose=False)

                if results[0].boxes is not None:
                    for box in results[0].boxes:
                        raw_class_id = int(box.cls.item())
                        track_id = int(box.id.item()) if box.id is not None else -1
                        if track_id < 0: continue

                        xyxy = box.xyxy[0].cpu().numpy()
                        x_center = (xyxy[0] + xyxy[2]) / 2

                        stable_class, pattern = self.get_stable_state(cam_idx, track_id, raw_class_id)
                        
                        if stable_class == 0: continue

                        # ğŸ”¥ ä¿®å¤ç‚¹ï¼šæ­£ç¡®è§£åŒ…ä¸‰ä¸ªè¿”å›å€¼
                        fused_dist, dist_geo, dist_width = self.calculate_fused_distance(xyxy, stable_class)
                        
                        azimuth = calculate_azimuth_planar(x_center, self.fx, self.cx)
                        bearing_body = wrap_deg_360(CAM_MOUNT_YAW_DEG.get(cam_idx, 0.0) + azimuth)

                        # è¿‡æ»¤å¤ªè¿œçš„å™ªç‚¹ (ä½¿ç”¨ fused_dist æ¯”è¾ƒï¼Œè€Œä¸æ˜¯ Tuple)
                        if fused_dist < 8.0:
                            data = {
                                'type': 'detection',
                                'cam_idx': cam_idx,
                                'track_id': track_id,
                                'class_id': stable_class,
                                'pattern': pattern,
                                'distance': round(fused_dist, 2),  # èåˆåçš„è·ç¦»
                                'dist_geo': round(dist_geo, 2),    # å‡ ä½•åŸå§‹å€¼
                                'dist_width': round(dist_width, 2),# å®½åº¦åŸå§‹å€¼
                                'bearing_body': round(bearing_body, 2)
                            }
                            try: self.queue.put_nowait(data)
                            except queue.Full: pass
        except Exception as e:
            print(f"Cam {cam_idx} Error: {e}")
        finally:
            cap.release()

    def run(self):
        print('ğŸš€ è§†è§‰ç³»ç»Ÿè¿è¡Œä¸­ (10Hz é™é¢‘è¾“å‡º)...')
        
        threads = []
        for idx in self.camera_indices:
            t = threading.Thread(target=self.camera_worker, args=(idx,), daemon=True)
            t.start()
            threads.append(t)

        try:
            while True:
                data = self.queue.get()
                
                if data['type'] == 'log':
                    print(data['message'])
                
                elif data['type'] == 'detection':
                    now = time.time()
                    if now - self.last_pub_time > PUBLISH_RATE_LIMIT:
                        
                        topic = "perception"
                        pub_data = {k:v for k,v in data.items() if k != 'type'}
                        self.socket.send_string(f"{topic} {json.dumps(pub_data)}")
                        self.last_pub_time = now
                        
                        cls_name = CLS_MAP.get(pub_data['class_id'], "UNK")
                        # æ‰“å°æ—¶æ˜¾ç¤ºæ›´å¤šè°ƒè¯•ä¿¡æ¯
                        print(f"ğŸ‘ï¸ [{cls_name}-{pub_data['cam_idx']}] "
                              f"Fus:{pub_data['distance']} | "
                              f"G:{pub_data['dist_geo']} W:{pub_data['dist_width']}")

                self.queue.task_done()
        except KeyboardInterrupt:
            print("ğŸ›‘ åœæ­¢ä¸­...")

    def cleanup(self):
        self.socket.close()
        self.context.term()

if __name__ == "__main__":
    pub = VisionPublisher(MODEL_PATH, CAMERA_INDICES, ZMQ_PORT)
    try:
        pub.run()
    except KeyboardInterrupt:
        pass
    finally:
        pub.cleanup()
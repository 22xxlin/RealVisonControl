#!/usr/bin/env python3
"""
æ–‡ä»¶: vision_pub.py (V3.0 èåˆæµ‹è·ç‰ˆ)
åŠŸèƒ½: è§†è§‰æ„ŸçŸ¥å‘å¸ƒ
å‡çº§ç‚¹:
  1. èåˆæµ‹è· (Fusion): ç»“åˆå®½åº¦æ³•ä¸å‡ ä½•æ³•ï¼Œåˆ©ç”¨å®½é«˜æ¯”åŠ¨æ€æŠ—é®æŒ¡ã€‚
  2. é²æ£’çŠ¶æ€ (Robust): ä¿ç•™è¿Ÿæ»é˜ˆå€¼ä¸çŠ¶æ€é”å®šã€‚
  3. ZMQ è¾“å‡ºé™é¢‘ (10Hz).
"""

import os
import sys
import cv2
import numpy as np
import time
import math
import json
import zmq
import queue
import threading
from collections import defaultdict, deque
from ultralytics import YOLO

# ================= é…ç½®åŒºåŸŸ =================
MODEL_PATH = "/home/nvidia/Downloads/Ros/ballCar2/weights/weights/best.engine"
CAMERA_INDICES = [0, 2, 4, 6]
ZMQ_PORT = 5555
PUBLISH_RATE_LIMIT = 0.1  # é™åˆ¶ ZMQ å‘é€é—´éš” (10Hz)
STATE_LOCK_DURATION = 0.5 # çŠ¶æ€åˆ‡æ¢é”å®šæ—¶é—´

# === ç‰©ç†ä¸å‡ ä½•å‚æ•° ===
# çœŸå®å®½åº¦ (å•ä½: ç±³)
CLASS_REAL_WIDTHS = {
    "car": 0.31,
    "basketball": 0.23,
    "flag": 0.13
}

# å‡ ä½•æµ‹è·é«˜åº¦å‚æ•° (å•ä½: ç±³)
CAM_HEIGHT = 0.15      # ç›¸æœºç¦»åœ°é«˜åº¦
OBJ_HEIGHT = 0.20      # å°è½¦å¡”é¡¶é«˜åº¦ (ä»…ç”¨äº 0-5 ç±»)

# ç›¸æœºå†…å‚ (è¯·æ ¹æ®å®é™…æ ‡å®šä¿®æ”¹)
CAM_INTRINSICS = {
    'fx': 498.0,
    'fy': 498.0,
    'cx': 331.2797,
    'cy': 156.1371
}

# Class ID æ˜ å°„
CLS_MAP = {
    0: "OFF", 1: "BLUE", 2: "RED", 3: "GREEN", 
    4: "PURPLE", 5: "GRAY", 6: "BALL", 7: "FLAG"
}

# ç›¸æœºæœå‘
CAM_MOUNT_YAW_DEG = {0: 180.0, 2: -90.0, 4: 0.0, 6: 90.0}

# ================= è¾…åŠ©å‡½æ•° =================
def calculate_azimuth_planar(x_pixel, fx, cx):
    pixel_offset = x_pixel - cx
    angle_rad = math.atan(pixel_offset / fx)
    angle_deg = math.degrees(angle_rad)
    return (angle_deg + 360.0) % 360.0 if angle_deg < 0 else angle_deg

def wrap_deg_360(a):
    return (a + 360.0) % 360.0

# ================= ä¸»ç±»å®šä¹‰ =================
class VisionPublisher:
    def __init__(self, model_path, camera_indices, zmq_port=5555, debounce_maxlen=30):
        self.model_path = model_path
        self.camera_indices = camera_indices
        self.zmq_port = zmq_port
        
        # åŠ è½½å†…å‚
        self.fx = CAM_INTRINSICS['fx']
        self.fy = CAM_INTRINSICS['fy']
        self.cx = CAM_INTRINSICS['cx']
        self.cy = CAM_INTRINSICS['cy']

        self.queue = queue.Queue(maxsize=100)
        self.context = zmq.Context()
        self.socket = self.context.socket(zmq.PUB)
        self.socket.bind(f"tcp://*:{self.zmq_port}")
        
        # å†å²ç¼“å­˜: Key=(cam_idx, track_id)
        self.history = defaultdict(lambda: deque(maxlen=debounce_maxlen))
        
        # çŠ¶æ€è®°å¿†
        self.state_memory = defaultdict(lambda: {'state': 0, 'pattern': 'OFF', 'last_switch_time': 0.0})
        
        # å‘å¸ƒé™é¢‘
        self.last_pub_time = 0.0

        print(f"âœ… è§†è§‰å‘å¸ƒè€…å¯åŠ¨ (èåˆæµ‹è·ç‰ˆ V3.0) | æ¨¡å‹: {self.model_path}")

    def initialize_camera(self, cam_idx):
        try:
            cap = cv2.VideoCapture(cam_idx, cv2.CAP_V4L2)
            if not cap.isOpened(): cap = cv2.VideoCapture(cam_idx)
            if cap.isOpened():
                cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
                cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
                cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)
                cap.set(cv2.CAP_PROP_FOURCC, cv2.VideoWriter_fourcc(*'MJPG'))
                return cap
        except Exception: pass
        return None

    def get_stable_state(self, cam_idx, track_id, current_class_id):
        """
        è¿Ÿæ»æ¯”è¾ƒ (Hysteresis) + çŠ¶æ€é”å®š (ä¿æŒåŸæœ‰é€»è¾‘ä¸å˜)
        """
        key = (cam_idx, track_id)
        mem = self.state_memory[key]
        now = time.time()

        if current_class_id >= 6: return current_class_id, "SOLID"

        self.history[key].append(current_class_id)
        buffer = list(self.history[key])

        colored_frames = [c for c in buffer if c in [1, 2, 3, 4, 5]]
        if not colored_frames: return 0, "OFF"

        from collections import Counter
        counts = Counter(colored_frames)
        dominant_color, count = counts.most_common(1)[0]
        color_ratio = count / len(buffer)
        
        if mem['pattern'] == 'SOLID':
            new_pattern = 'FLASH' if color_ratio < 0.80 else 'SOLID'
        else:
            new_pattern = 'SOLID' if color_ratio > 0.90 else 'FLASH'

        if new_pattern != mem['pattern'] or dominant_color != mem['state']:
            if now - mem['last_switch_time'] < STATE_LOCK_DURATION:
                return mem['state'], mem['pattern']
            else:
                mem['state'] = dominant_color
                mem['pattern'] = new_pattern
                mem['last_switch_time'] = now
                return dominant_color, new_pattern
        else:
            return dominant_color, new_pattern

    def calculate_fused_distance(self, bbox_xyxy, class_id):
        """
        ğŸ”¥ æ ¸å¿ƒå‡çº§ï¼šèåˆæµ‹è·ç®—æ³•
        """
        x1, y1, x2, y2 = bbox_xyxy
        box_width = x2 - x1
        box_height = y2 - y1
        
        # 1. åŸºç¡€æ£€æŸ¥
        if box_width <= 0 or box_height <= 0: return 999.0

        # --- A. å®½åº¦æµ‹è·æ³• (é€šç”¨) ---
        if class_id == 6: real_w = CLASS_REAL_WIDTHS["basketball"]
        elif class_id == 7: real_w = CLASS_REAL_WIDTHS["flag"]
        else: real_w = CLASS_REAL_WIDTHS["car"]
        
        dist_width = (real_w * self.fx) / box_width

        # --- B. èåˆé€»è¾‘ (ä»…é’ˆå¯¹å°è½¦ 0-5) ---
        if 0 <= class_id <= 5:
            # 1. å‡ ä½•æµ‹è· (å‡è®¾å€’ç«‹æ‘„åƒå¤´ï¼Œå– y2 ä¸ºå¡”é¡¶)
            # æ³¨æ„ï¼šå¦‚æœä½ çš„æ‘„åƒå¤´ä¸æ˜¯å€’ç«‹å®‰è£…ï¼Œè¯·æ£€æŸ¥è¿™é‡Œæ˜¯å¦åº”è¯¥ç”¨ y1
            y_top_pixel = y2 
            v = y_top_pixel - self.cy
            
            # é˜²é™¤é›¶å’Œå™ªç‚¹
            if abs(v) < 1e-5: v = 1e-5
            
            # è®¡ç®—ä¿¯ä»°è§’ (å‡è®¾å®‰è£…Pitch=0ï¼Œä¸ä¾èµ–IMU)
            alpha = math.atan(v / self.fy)
            total_angle = alpha + 0.0 
            
            dH = OBJ_HEIGHT - CAM_HEIGHT
            
            if total_angle > 0.001:
                dist_geo = abs(dH / math.tan(total_angle))
            else:
                dist_geo = 99.9 # è§†ä½œæ— ç©·è¿œæˆ–æ— æ•ˆ

            # 2. å®½é«˜æ¯”æ£€æŸ¥ (é®æŒ¡æ£€æµ‹)
            current_ratio = box_width / box_height
            # é˜ˆå€¼ï¼šæ ‡å‡†æ¯”ä¾‹çº¦ 1.55 (0.31/0.2)ã€‚è‹¥å°äº 0.9 è¯´æ˜ä¸¥é‡å˜çª„(è¢«é®æŒ¡)
            OCCLUSION_THRESHOLD = 0.9 

            if dist_geo < 15.0: # å‡ ä½•æ³•åœ¨æè¿œè·ç¦»ä¸å¯ä¿¡ï¼Œä»…åœ¨è¿‘å¤„èåˆ
                if current_ratio < OCCLUSION_THRESHOLD:
                    # âš ï¸ åˆ¤å®šä¸ºé®æŒ¡ -> å…¨ä¿¡å‡ ä½•æ³•
                    return dist_geo
                else:
                    # âœ… åˆ¤å®šä¸ºæ­£å¸¸ -> åŠ æƒèåˆ (0.4å‡ ä½• + 0.6å®½åº¦)
                    # å®½åº¦æ³•æƒé‡é«˜ä¸€ç‚¹ä»¥å‡å°‘é¢ ç°¸å½±å“
                    return 0.4 * dist_geo + 0.6 * dist_width
            else:
                return dist_width
        
        # éå°è½¦ (çƒã€æ——å­) ç›´æ¥è¿”å›å®½åº¦è·ç¦»
        return dist_width

    def camera_worker(self, cam_idx):
        try:
            model = YOLO(self.model_path)
            self.queue.put({'type': 'log', 'message': f'âœ… Cam {cam_idx}: Ready'})
        except Exception as e:
            self.queue.put({'type': 'log', 'message': f'âŒ Cam {cam_idx}: {e}'})
            return

        cap = self.initialize_camera(cam_idx)
        if cap is None: return

        try:
            while True:
                ret, frame = cap.read()
                if not ret: 
                    time.sleep(0.1); continue

                results = model.track(frame, conf=0.45, iou=0.6, imgsz=(480, 640), persist=True, verbose=False)

                if results[0].boxes is not None:
                    for box in results[0].boxes:
                        raw_class_id = int(box.cls.item())
                        track_id = int(box.id.item()) if box.id is not None else -1
                        if track_id < 0: continue

                        xyxy = box.xyxy[0].cpu().numpy()
                        x_center = (xyxy[0] + xyxy[2]) / 2

                        stable_class, pattern = self.get_stable_state(cam_idx, track_id, raw_class_id)
                        
                        if stable_class == 0: continue

                        # ğŸ”¥ è°ƒç”¨æ–°çš„èåˆæµ‹è·å‡½æ•°
                        distance = self.calculate_fused_distance(xyxy, stable_class)
                        
                        azimuth = calculate_azimuth_planar(x_center, self.fx, self.cx)
                        bearing_body = wrap_deg_360(CAM_MOUNT_YAW_DEG.get(cam_idx, 0.0) + azimuth)

                        # è¿‡æ»¤å¤ªè¿œçš„å™ªç‚¹
                        if distance < 8.0:
                            data = {
                                'type': 'detection',
                                'cam_idx': cam_idx,
                                'track_id': track_id,
                                'class_id': stable_class,
                                'pattern': pattern,
                                'distance': round(distance, 2),
                                'bearing_body': round(bearing_body, 2)
                            }
                            try: self.queue.put_nowait(data)
                            except queue.Full: pass
        except Exception as e:
            print(f"Cam {cam_idx} Error: {e}")
        finally:
            cap.release()

    def run(self):
        print('ğŸš€ è§†è§‰ç³»ç»Ÿè¿è¡Œä¸­ (10Hz é™é¢‘è¾“å‡º)...')
        
        threads = []
        for idx in self.camera_indices:
            t = threading.Thread(target=self.camera_worker, args=(idx,), daemon=True)
            t.start()
            threads.append(t)

        try:
            while True:
                data = self.queue.get()
                
                if data['type'] == 'log':
                    print(data['message'])
                
                elif data['type'] == 'detection':
                    now = time.time()
                    if now - self.last_pub_time > PUBLISH_RATE_LIMIT:
                        
                        topic = "perception"
                        pub_data = {k:v for k,v in data.items() if k != 'type'}
                        self.socket.send_string(f"{topic} {json.dumps(pub_data)}")
                        self.last_pub_time = now
                        
                        cls_name = CLS_MAP.get(pub_data['class_id'], "UNK")
                        print(f"ğŸ‘ï¸ [{cls_name}-{pub_data['cam_idx']}] {pub_data['pattern']:<5} | D={pub_data['distance']}m")

                self.queue.task_done()
        except KeyboardInterrupt:
            print("ğŸ›‘ åœæ­¢ä¸­...")

    def cleanup(self):
        self.socket.close()
        self.context.term()

if __name__ == "__main__":
    pub = VisionPublisher(MODEL_PATH, CAMERA_INDICES, ZMQ_PORT)
    try:
        pub.run()
    except KeyboardInterrupt:
        pass
    finally:
        pub.cleanup()